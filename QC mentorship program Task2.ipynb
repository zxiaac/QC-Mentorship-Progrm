{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5a4df5a",
   "metadata": {},
   "source": [
    "## Task 2\n",
    "\n",
    "\n",
    "Prepare $4$ random $4$-qubit quantum states of your choice. \n",
    "  \n",
    "  \n",
    "Create and train a variational circuit that transforms input states into predefined output states. Namely  \n",
    "if random state $1$ is provided, it returns state $\\left|0011\\right>$  \n",
    "if random state $2$ is provided, it returns state $\\left|0101\\right>$  \n",
    "if random state $3$ is provided, it returns state $\\left|1010\\right>$  \n",
    "if random state $4$ is provided, it returns state $\\left|1100\\right>$\n",
    "What would happen if you provided a different state?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62183aff",
   "metadata": {},
   "source": [
    "## Solution\n",
    "1. The chosen random states are $\\left|0000\\right>$, $\\left|0011\\right>$, $\\left|0111\\right>$, $\\left|1011\\right>$.  \n",
    "2. Then I use them as the initial state of QNN $U(\\theta)$, and apply the built-in entangled layers (consists of rotation gates and CNOT gates) to the initial states, and run the circuit, and get the final output state $U(\\theta)\\left|0000\\right>$.  \n",
    "3. Repeat Step $2$ for four times, and get the all four output states$U(\\theta)\\left|0000\\right>$, $U(\\theta)\\left|0011\\right>$, $U(\\theta)\\left|0111\\right>$, $U(\\theta)\\left|1011\\right>$.  \n",
    "4. Calculate the square of inner products between the output states and the target states, and add them together as the loss function, i.e., $\\mathcal{L}=\\sum\\limits_{i=1}^{4}\\left|\\left<{\\psi_i}\\right|\\left|{\\phi_i}\\right>\\right|^2=\\left|\\left<0000\\right|U(\\theta)^\\dagger\\left|0011\\right>\\right|^2+\\left|\\left<0011\\right|U(\\theta)^\\dagger\\left|0101\\right>\\right|^2+\\left|\\left<0111\\right|U(\\theta)^\\dagger\\left|1010\\right>\\right|^2+\\left|\\left<1011\\right|U(\\theta)^\\dagger\\left|1100\\right>\\right|^2$  \n",
    "5. Use Adam optimizer to minimize the loss.  \n",
    "6. Update the parameters in the QNN.  \n",
    "7. Repeat Step $2-6$ for $120$ iterations and get the optimal parameters in the QNN.  \n",
    "   \n",
    "As you can see, the final loss after training is $-4$, which is desired value, since all inner product are equal to $1$, which means the output states are indeed the target states given the chosen input.     \n",
    "    \n",
    "The whole QNN is a unitary, it maps from a set of basis to another set of basis. In this case, it maps $\\left|0000\\right>$ to $\\left|0011\\right>$, $\\left|0011\\right>$ to $\\left|0101\\right>$, $\\left|0111\\right>$ to $\\left|1010\\right>$, and $\\left|1011\\right>$ to $\\left|1100\\right>$. It can be seen as a $16\\times 16$ matrix, and four columns are determined, while other $12$ columns does not matter and depends on the optimization process. So if superpositions of $\\left|0000\\right>$, $\\left|0011\\right>$, $\\left|0111\\right>$, $\\left|1011\\right>$ are given, then the output will be the superpositions of the four target states. Otherwise, it will depend on the other $12$ colmns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68802338",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zihanxia/anaconda3/envs/paddle_quantum/lib/python3.7/site-packages/ipykernel/pylab/backend_inline.py:164: DeprecationWarning: `configure_inline_support` is deprecated since IPython 7.23, directly use `matplotlib_inline.backend_inline.configure_inline_support()`\n",
      "  configure_inline_support(ip, backend)\n"
     ]
    }
   ],
   "source": [
    "import paddle\n",
    "from paddle_quantum.circuit import UAnsatz\n",
    "\n",
    "import numpy as np\n",
    "from numpy import pi as PI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "981f04a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zihanxia/anaconda3/envs/paddle_quantum/lib/python3.7/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "def U_theta(theta, N, D, initial_state, target_state):\n",
    "    \"\"\"\n",
    "    Quantum Neural Network\n",
    "    \"\"\"\n",
    "    # Initialize the quantum neural network according to the number of qubits N\n",
    "    cir = UAnsatz(N)\n",
    "    # Built-in {R_y + CNOT + U3} circuit template\n",
    "    cir.complex_entangled_layer(theta[:D], D)\n",
    "    # Lay R_y gates in the last row\n",
    "    for i in range(N):\n",
    "        cir.ry(theta=theta[D][i][0], which_qubit=i)\n",
    "    # The quantum neural network acts on one of the random initial states\n",
    "    fin_state = cir.run_state_vector(initial_state).reshape((2**N, 1))\n",
    "    # calculate the hermitian conjuagte the output state\n",
    "    fin_state_conj = paddle.conj(fin_state).transpose(perm=(1, 0))\n",
    "    # comput the inner product between the two states\n",
    "    inner_prod = paddle.matmul(fin_state_conj, target_state)\n",
    "    # compute the square of the inner product, and use it as the loss\n",
    "    loss = - paddle.real(paddle.multiply(inner_prod, paddle.conj(inner_prod)))\n",
    "\n",
    "    return loss, cir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "436384c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StateNet(paddle.nn.Layer):\n",
    "    \"\"\"\n",
    "    Construct the model net\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, shape, dtype=\"float64\"):\n",
    "        super(StateNet, self).__init__()\n",
    "        \n",
    "        # Initialize the list of theta parameters, filling the initial values with a uniform distribution of [0, 2* PI]  \n",
    "        self.theta = self.create_parameter(shape=shape, \n",
    "                                           default_initializer=paddle.nn.initializer.Uniform(low=0.0, high=2*PI),\n",
    "                                           dtype=dtype, is_bias=False)\n",
    "        \n",
    "   # Define loss function and forward propagation mechanism\n",
    "    def forward(self, N, D):\n",
    "        \n",
    "        # get the randomly chosen four states |0000>,|0011>,|0111>,|1011>\n",
    "        initial_state = []\n",
    "        initial_state.append(paddle.to_tensor(np.eye(2**N)[0], 'complex128'))\n",
    "        initial_state.append(paddle.to_tensor(np.eye(2**N)[4], 'complex128'))\n",
    "        initial_state.append(paddle.to_tensor(np.eye(2**N)[8], 'complex128'))\n",
    "        initial_state.append(paddle.to_tensor(np.eye(2**N)[12], 'complex128'))\n",
    "        # construct the target four states |0011>,|0101>,|1010>,|1100>\n",
    "        states = []\n",
    "        states.append(paddle.to_tensor(np.eye(2**N)[2], 'float64'))\n",
    "        states.append(paddle.to_tensor(np.eye(2**N)[4], 'float64'))\n",
    "        states.append(paddle.to_tensor(np.eye(2**N)[9], 'float64'))\n",
    "        states.append(paddle.to_tensor(np.eye(2**N)[11], 'float64'))\n",
    "        # for each given initial state, calculate the loss, and add them together as the final loss\n",
    "        final_loss, cir = U_theta(self.theta, N, D, initial_state[0], states[0])\n",
    "        for i in range(3):\n",
    "            loss, cir = U_theta(self.theta, N, D, initial_state[i+1], states[i+1])\n",
    "            final_loss += loss\n",
    "\n",
    "        return final_loss, cir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ea7b8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "ITR = 120  # Set the number of optimization iterations\n",
    "LR = 0.2   # Set the learning rate\n",
    "D = 6      # Set the depth of the repetitive calculation module in QNN\n",
    "N = 4 # number of qubits = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d80d2680",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zihanxia/anaconda3/envs/paddle_quantum/lib/python3.7/site-packages/paddle/tensor/creation.py:125: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  if data.dtype == np.object:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: 20 loss: -3.7913\n",
      "iter: 40 loss: -3.9635\n",
      "iter: 60 loss: -3.9970\n",
      "iter: 80 loss: -3.9993\n",
      "iter: 100 loss: -3.9999\n",
      "iter: 120 loss: -4.0000\n",
      "\n",
      "Circuit after training:\n",
      "--U----*--------------x----U----*--------------x----U----*--------------x----U----*--------------x----U----*--------------x----U----*--------------x----Ry(6.283)--\n",
      "       |              |         |              |         |              |         |              |         |              |         |              |               \n",
      "--U----x----*---------|----U----x----*---------|----U----x----*---------|----U----x----*---------|----U----x----*---------|----U----x----*---------|----Ry(1.570)--\n",
      "            |         |              |         |              |         |              |         |              |         |              |         |               \n",
      "--U---------x----*----|----U---------x----*----|----U---------x----*----|----U---------x----*----|----U---------x----*----|----U---------x----*----|----Ry(-0.00)--\n",
      "                 |    |                   |    |                   |    |                   |    |                   |    |                   |    |               \n",
      "--U--------------x----*----U--------------x----*----U--------------x----*----U--------------x----*----U--------------x----*----U--------------x----*----Ry(0.001)--\n",
      "                                                                                                                                                                   \n"
     ]
    }
   ],
   "source": [
    "# Determine the parameter dimensions of the network \n",
    "net = StateNet(shape=[D + 1, N, 3])\n",
    "\n",
    "# use the Adam optimizer to obtain relatively good convergence\n",
    "opt = paddle.optimizer.Adam(learning_rate=LR, parameters=net.parameters())\n",
    "\n",
    "# Optimize iterations\n",
    "for itr in range(1, ITR + 1):\n",
    "\n",
    "    # Forward propagation calculates the loss function\n",
    "    loss, cir = net(N, D)\n",
    "\n",
    "    # Back propagation minimizes the loss function\n",
    "    loss.backward()\n",
    "    opt.minimize(loss)\n",
    "    opt.clear_grad()\n",
    "\n",
    "    # Print results\n",
    "    if itr % 20 == 0:\n",
    "        print(\"iter:\", itr, \"loss:\", \"%.4f\" % paddle.cast(loss, 'float64').numpy())\n",
    "    if itr == ITR:\n",
    "        print(\"\\nCircuit after training:\") \n",
    "        print(cir)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
